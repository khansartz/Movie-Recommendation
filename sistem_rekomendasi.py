# -*- coding: utf-8 -*-
"""sistem rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t6SqXCoIFcyQRSifOgIy5SiZ9NtdNYu0

# **Proyek Machine Learning – Khansa Maritza A**

# **Latar Belakang**
Seiring berkembangnya internet dan melimpahnya informasi digital, kebutuhan akan sistem rekomendasi yang efektif semakin penting untuk membantu pengguna menyaring informasi yang relevan. Salah satu pendekatan yang banyak digunakan adalah content-based filtering, yang merekomendasikan item berdasarkan kemiripan konten dengan preferensi pengguna sebelumnya. Menurut Lü et al. (2012), sistem rekomendasi telah menjadi fokus penting di berbagai bidang karena kemampuannya menyederhanakan pengambilan keputusan dalam ruang informasi yang luas.

Selain itu, collaborative filtering juga menjadi teknik dominan karena kemampuannya memanfaatkan pola penilaian pengguna lain untuk memberikan rekomendasi yang lebih personal. Ekstrand et al. (2011) menyatakan bahwa sistem ini tidak bersifat satu-ukuran-untuk-semua, dan efektivitasnya sangat tergantung pada konteks pengguna serta tugas yang ingin didukung. Oleh karena itu, proyek ini mengembangkan dua pendekatan tersebut untuk menyediakan rekomendasi film yang relevan dan disesuaikan dengan perilaku serta preferensi pengguna.

Referensi:
- Lü, L., Medo, M., Yeung, C. H., Zhang, Y. C., Zhang, Z. K., & Zhou, T. (2012). Recommender systems. Physics Reports, 519(1), 1–49.
- Ekstrand, M. D., Riedl, J. T., & Konstan, J. A. (2011). Collaborative filtering recommender systems. Foundations and Trends® in Human–Computer Interaction, 4(2), 81–173.


# **Tujuan Proyek**
- Mengembangkan sistem rekomendasi berbasis content-based filtering yang dapat menyarankan film kepada pengguna berdasarkan kemiripan genre dan metadata film yang disukai sebelumnya.
- Mengembangkan sistem rekomendasi berbasis collaborative filtering dengan memanfaatkan data rating dari pengguna lain untuk menyarankan film yang relevan.
- Memberikan top-N recommendations (misalnya 10 film) yang dipersonalisasi dan relevan terhadap preferensi atau perilaku pengguna.

# **Impor Dataset**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""# **Load Dataset**"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d parasharmanas/movie-recommendation-system
!unzip movie-recommendation-system.zip

"""## **Memuat Dataset**
Dataset film dan data penilaian dimuat dari file CSV, kemudian dilakukan pengecekan jumlah film unik dan pengguna unik pada data penilaian untuk mendapatkan gambaran awal dataset.
"""

movies = pd.read_csv('/content/movies.csv')
ratings = pd.read_csv('/content/ratings.csv')

print('Jumlah data film : ', len(movies.movieId.unique()))
print('Jumlah data penilaian pada film: ', len(ratings.userId.unique()))

"""# Univariate Exploratory Data Analysis

## **1. Movies Variabel**
Melakukan pemeriksaan informasi struktur data `movies`, menghitung jumlah data film unik, serta menampilkan jenis-jenis genre film yang terdapat pada dataset untuk memahami karakteristik variabel `movies`.
Fungsi `movies.info()` digunakan untuk menampilkan ringkasan struktur dataset:

- Total terdapat 62423 data dan 3 kolom.
- Tidak terdapat nilai yang hilang (non-null semua).
- Kolom movieId bertipe numerik (int64), dan title serta genres bertipe kategorikal (object).
"""

movies.info()

print('Banyak data: ', len(movies.movieId.unique()))
print('Jenis genre film: ', movies.genres.unique())

# Cek jumlah missing values per kolom
movies.isnull().sum()

# Cek apakah ada baris duplikat
movies.duplicated().sum()

"""### **Visualisasi Top 10 Genre**
Visualisasi ini menampilkan 10 genre film yang paling sering muncul dalam dataset. Data genre awalnya dipisahkan dari kolom genres, yang memiliki format gabungan dengan tanda pemisah "|", lalu dipecah menjadi baris-baris terpisah agar setiap genre dapat dihitung secara individual.
"""

# Pecah genre per baris
genre_split = movies['genres'].str.split('|').explode()

# Hitung frekuensi tiap genre
genre_counts = genre_split.value_counts().head(10)

# Visualisasi
plt.figure(figsize=(10, 6))
sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='viridis')
plt.title('Top 10 Most Frequent Movie Genres')
plt.xlabel('Jumlah Film')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""## **2. Ratings Variabel**
Melakukan pemeriksaan struktur data `ratings`, menampilkan beberapa data awal, serta menghitung statistik deskriptif dan jumlah unik pengguna, film, dan total data rating untuk memahami karakteristik variabel `ratings`.
Fungsi `ratings.info()` digunakan untuk menampilkan ringkasan struktur dataset:

- Total terdapat 25000095 data dan 4 kolom.
- Semua kolom bertipe numerik (int64 dan  float64).
"""

ratings.info()

ratings.head()

ratings.describe()

print('Jumlah userId: ', len(ratings.userId.unique()))
print('Jumlah moviesId: ', len(ratings.movieId.unique()))
print('Jumlah data rating: ', len(ratings))

# Cek jumlah missing values per kolom
ratings.isnull().sum()

# Cek apakah ada baris duplikat
ratings.duplicated().sum()

"""### **Distribusi Skor Rating Film**
Berdasarkan visualisasi distribusi skor rating, diketahui bahwa tiga skor rating yang paling sering diberikan oleh pengguna adalah 4.0, 3.0, dan 5.0. Hal ini menunjukkan bahwa mayoritas pengguna cenderung memberikan penilaian yang positif hingga sangat positif terhadap film yang mereka tonton.
"""

plt.figure(figsize=(8, 5))
sns.countplot(data=ratings, x='rating', palette='mako', order=sorted(ratings['rating'].unique()))
plt.title('Distribusi Skor Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.tight_layout()
plt.show()

"""# Data Preprocessing

## **1. Menggabungkan dataset ratings dan movies berdasarkan kolom movieId**
Dilakukan penggabungan data ratings dan movies berdasarkan movieId menggunakan join kiri.
- Kolom timestamp dihapus karena tidak diperlukan dalam analisis.
- Data hasil penggabungan disimpan dalam variabel `df`.
"""

# Merge ratings sama movies berdasarkan movieId
df = pd.merge(ratings, movies, on='movieId', how='left')

# Hapus kolom yang tidak terpakai
df = df.drop(columns=['timestamp'])
df

"""## **2. Pengecekan Missing Value**
Dilakukan pengecekan nilai yang hilang (missing value) pada seluruh kolom dataframe df.
"""

# Mengecek missing value pada dataframe df
df.isnull().sum()

"""## **3. Pengurutan dan Pengambilan Sampel Data**
Data df diurutkan berdasarkan movieId secara menaik, kemudian diambil sampel sebanyak 100.000 baris secara acak untuk mengurangi penggunaan memori saat proses analisis selanjutnya.
"""

# Mengurutkan df berdasarkan movieId
df_fix = df.sort_values('movieId', ascending=True)

# Mengambil sample sebanyak 10000 baris agar tidak memakan banyak RAM
df_fix = df.sample(100000, random_state=42)
df_fix

"""## **4. Mengecek Jumlah Film Unik dan Kategori Genre**
Menghitung jumlah film unik yang ada pada dataframe df_fix dan menampilkan kategori genre film yang terdapat pada data tersebut untuk memahami keberagaman data.
"""

# Mengecek berapa jumlah film unik di df_fix
len(df_fix.movieId.unique())

# Mengecek kategori genre yang unik di df_fix
df_fix.genres.unique()

"""## **5. Persiapan Data untuk Analisis Selanjutnya**
Membuat variabel preparation yang berisi dataframe df_fix dan mengurutkannya berdasarkan movieId.
Selanjutnya, data duplikat berdasarkan movieId dihapus untuk mendapatkan data film yang unik.
"""

# Membuat variabel preparation yang berisi dataframe df_fix kemudian mengurutkan berdasarkan movieId
preparation = df_fix
preparation.sort_values('movieId')

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('movieId')
preparation

"""## **6. Konversi Data ke Bentuk List dan Membuat DataFrame Baru**
Data pada kolom `movieId`, `title`, dan `genres` diubah dari Series menjadi list untuk mempermudah pengolahan data selanjutnya.
Kemudian, list tersebut dikumpulkan kembali menjadi sebuah DataFrame baru dengan kolom `id`, `title`, dan `genre`.
"""

# Mengonversi data series 'movie_id' menjadi dalam bentuk list
movie_id = preparation['movieId'].tolist()

# Mengonversi data series 'movie_name' menjadi dalam bentuk list
movie_name = preparation['title'].tolist()

# Mengonversi data series 'movie_genre' menjadi dalam bentuk list
movie_genre = preparation['genres'].tolist()

print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

movie_new = pd.DataFrame({
    'id': movie_id,
    'title': movie_name,
    'genre': movie_genre
})
movie_new

data = movie_new
data.sample(5)

"""# Model Development Content Based Filtering

## **1. Data Preparation**
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tf.fit(data['genre'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""### **Preprocessing Genre**
Genre yang memiliki label tidak jelas seperti (no genres listed) diganti menjadi 'Unknown', dan format diseragamkan (contoh: 'Sci-Fi' diubah menjadi 'SciFi').
"""

# Cek film yang punya genre "no"
movie_new[movie_new['genre'].str.contains(r'\bno\b', case=False, regex=True)]

# Cek film yang punya genre "fi"
movie_new[movie_new['genre'].str.contains(r'\bfi\b', case=False, regex=True)]

# Mengganti "no genres listed" menjadi "Unknown"
movie_new['genre'] = movie_new['genre'].replace('(no genres listed)', 'Unknown')
movie_new[movie_new['genre'].str.contains(r'Unknown', case=False, regex=True)]

# Mengganti "Sci-Fi" menjadi "SciFi"
movie_new['genre'] = movie_new['genre'].str.replace('Sci-Fi', 'SciFi')
movie_new[movie_new['genre'].str.contains(r'SciFi', case=False, regex=True)]

"""### **TF-IDF Vectorizer**
Data genre film diproses menggunakan TF-IDF Vectorizer untuk mengubah teks genre menjadi representasi numerik yang dapat digunakan dalam model rekomendasi berbasis konten.
- Genre diubah menjadi matriks TF-IDF dan dicek ukuran matriks hasil transformasi.
- Matriks TF-IDF dikonversi ke bentuk matriks padat (dense matrix) untuk memudahkan visualisasi.
- Dibuat DataFrame dari matriks TF-IDF dengan kolom genre dan baris nama film agar bisa dilihat nilai bobot TF-IDF pada masing-masing genre per film secara sampel.
"""

# Cek mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Fit dan transform genre jadi matriks TF-IDF
tfidf_matrix = tf.fit_transform(data['genre'])

# Cek ukuran matriks
print(tfidf_matrix.shape)

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan genre film
# Baris diisi dengan nama film

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.title
).sample(22, axis=1, replace=True).sample(10, axis=0)

"""## **Modeling**

## **1. Cosine Similarity**
Melakukan perhitungan cosine similarity pada matriks TF-IDF untuk mengukur tingkat kemiripan antar film berdasarkan genre.
- Hasil cosine similarity disimpan dalam sebuah matriks persegi dan dikonversi menjadi DataFrame dengan indeks dan kolom berupa nama film.
- Matriks ini memperlihatkan seberapa mirip setiap film satu sama lain dari segi genre, yang nantinya berguna untuk sistem rekomendasi berbasis konten.
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama film
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['title'], columns=data['title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap film
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## **2. Mendapatkan Rekomendasi**
Membuat fungsi movie_recommendations yang menerima input judul film dan mengembalikan daftar film rekomendasi berdasarkan kemiripan genre menggunakan cosine similarity.
- Fungsi ini mencari film dengan nilai similarity tertinggi terhadap film input.
- Hasil rekomendasi disajikan dalam bentuk DataFrame yang menyertakan nama film dan genre.
- Film yang sama dengan input dihilangkan agar tidak muncul di rekomendasi.
"""

def movie_recommendations(title, similarity_data=cosine_sim_df, items=movie_new[['title', 'genre']], k=5):
    """
    Rekomendasi film berdasarkan kemiripan genre film.

    Parameter:
    ---
    title : str
        Judul film yang mau dicari rekomendasinya (harus ada di index similarity dataframe)
    similarity_data : pd.DataFrame
        Dataframe kemiripan (cosine similarity) simetrik antar film
    items : pd.DataFrame
        Data film berisi nama film dan genre
    k : int
        Jumlah rekomendasi yang mau ditampilkan
    """

    # Ambil posisi k film dengan similarity terbesar ke title
    index = similarity_data.loc[:, title].to_numpy().argpartition(range(-1, -k-1, -1))

    # Ambil nama film dengan similarity tertinggi
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Hapus title agar tidak muncul di rekomendasi
    closest = closest.drop(title, errors='ignore')

    # Merge dengan data film asli biar dapet info genre dll
    return pd.DataFrame(closest, columns=['title']).merge(items, on='title').head(k)

data[data.title.eq('Butter (2011)')]

# Mendapatkan rekomendasi film yang mirip
movie_recommendations('Butter (2011)')

"""## **3. Hasil Evaluasi**
Model content-based filtering memberikan rekomendasi berdasarkan kesamaan fitur antar film, khususnya genre. Misalnya, ketika pengguna memilih film Butter (2011) yang bergenre Comedy, sistem memberikan lima rekomendasi film lain yang juga bergenre Comedy:
- Meatballs III (1987)
- Serial (1980)
- Specials, The (2000)
- How to Stuff a Wild Bikini (1965)
- Blackadder Back & Forth (1999)

Kelima film memiliki genre yang relevan dengan film yang dipilih.

**Kesimpulan:**
Model content-based filtering menunjukkan performa yang sangat baik dalam menjaga konsistensi genre dalam rekomendasinya. Precision@5 yang mencapai 100% menunjukkan bahwa sistem ini efektif dalam merekomendasikan film dengan karakteristik yang serupa, cocok untuk pengguna dengan preferensi genre yang spesifik.

# Model Development dengan Collaborative Filtering
Pengembangan model rekomendasi berbasis collaborative filtering menggunakan data rating film.
- Dataset ratings disampling sebanyak 100.000 baris agar tidak memakan banyak RAM.
"""

# Membaca dataset
df = ratings
df = df.sample(100000, random_state=42)
df

"""## **Data Preparation**

## **1. Encoding**
- Proses encoding `userId` dan `movieId` ke angka agar mudah diproses model.
- Mengambil list `userId` dan `movieId` unik.
- Membuat dictionary untuk mapping `userId` dan `movieId` ke angka dan sebaliknya (encode dan decode).
- Menambahkan kolom baru `user` dan `movie` pada DataFrame hasil mapping tersebut.
"""

# Mengubah userID menjadi list unik
user_ids = df['userId'].unique().tolist()
print('list userId:', user_ids)

# Encode userID jadi angka
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId:', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId:', user_encoded_to_user)

# Mengubah movieId menjadi list unik
movie_ids = df['movieId'].unique().tolist()

# Encoding movieId → angka
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Decoding angka → movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Mapping userId dan movieId ke bentuk encoded
df['user'] = df['userId'].map(user_to_user_encoded)
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

"""##**2. Pemeriksaan dan Informasi Dataset Setelah Encoding**
Melakukan pemeriksaan hasil mapping userId dan movieId ke angka:
- Menampilkan contoh mapping pada beberapa baris awal.
- Menghitung jumlah user unik dan movie unik setelah encoding.
- Mengubah tipe data rating menjadi float32 untuk efisiensi komputasi.
- Mengambil nilai rating minimum dan maksimum sebagai informasi rentang rating.
"""

# Cek hasil mapping
df[['userId', 'user', 'movieId', 'movie']].head()

# Jumlah user unik (yang udah di-encode)
num_users = len(user_to_user_encoded)
print("Jumlah user:", num_users)

# Jumlah movie unik (yang udah di-encode)
num_movies = len(movie_encoded_to_movie)
print("Jumlah movie:", num_movies)

# Convert rating ke float32
df['rating'] = df['rating'].values.astype(np.float32)

# Ambil min & max rating
min_rating = df['rating'].min()
max_rating = df['rating'].max()

print('Number of Users: {}, Number of Movies: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movies, min_rating, max_rating
))

"""## **3. Membagi Data untuk Training dan Validasi**
Melakukan persiapan data sebelum masuk ke model training:
- Dataset diacak supaya distribusi data acak dan gak bias.
- Fitur input berupa kombinasi user dan movie dalam bentuk array.
- Target (rating) dinormalisasi ke rentang 0 sampai 1 supaya model lebih gampang belajar dan stabil.
- Data dibagi jadi 2: 80% untuk training, 20% untuk validasi performa model.
- Cetak bentuk data (shape) untuk memastikan ukuran data sudah benar.
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Gabung user & movie jadi satu array
x = df[['user', 'movie']].values

# Normalisasi rating ke range 0-1 biar cocok buat training
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Split 80% buat training, 20% buat validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

# Buat ngecek bentuknya
print("x shape:", x.shape)
print("y shape:", y.shape)
print(x, y)

"""## **Modeling**

## **1. Proses Training**
- Membangun Arsitektur Model RecommenderNet
Model ini pake embedding buat representasi user dan movie dalam ruang vektor berdimensi kecil (embedding size = 50).
Ada 2 embedding:
  - User embedding + bias user
  - Movie embedding + bias movie
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Arsitektur model rekomendasi
class RecommenderNet(tf.keras.Model):

    def __init__(self, num_users, num_movies, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_movies = num_movies
        self.embedding_size = embedding_size

        # Embedding user
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)

        # Embedding movie
        self.movie_embedding = layers.Embedding(
            num_movies,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.movie_bias = layers.Embedding(num_movies, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        movie_vector = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])

        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)
        x = dot_user_movie + user_bias + movie_bias

        return tf.nn.sigmoid(x)

"""**Inisialisasi dan Compile Model**
- Loss function: BinaryCrossentropy (karena rating sudah dinormalisasi ke 0-1, diperlakukan kayak klasifikasi biner).
- Optimizer: Adam dengan learning rate 0.001.
- Metrics: Root Mean Squared Error (RMSE) untuk evaluasi kesalahan prediksi.

**Training Model**
- Batch size kecil (8) supaya update model lebih sering.
- Latih selama 50 epoch menggunakan data validasi untuk cek performa model selama training.
"""

# Inisialisasi model
model = RecommenderNet(num_users, num_movies, embedding_size=50)

# Compile model
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Training model
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=8,
    epochs=50,
    validation_data=(x_val, y_val)
)

"""**Visualisasi Training**
- Plot grafik RMSE training dan validasi per epoch untuk untuk mengukur performa model dalam memprediksi nilai numerik.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## **2. Mendapatkan Rekomendasi Film**
- Ambil satu user secara acak dari data rating.
- Identifikasi film yang belum ditonton oleh user tersebut.
- Prediksi rating untuk film yang belum ditonton menggunakan model.
- Ambil 10 film dengan prediksi rating tertinggi sebagai rekomendasi.
- Tampilkan 5 film favorit user dan 10 rekomendasi terbaik berdasarkan hasil prediksi.
"""

movie_df = data
df = pd.read_csv('ratings.csv')  # dataset rating user terhadap film

# Ambil sample user random
user_id = df.userId.sample(1).iloc[0]
movies_watched_by_user = df[df.userId == user_id]

# Ambil film yang belum ditonton user
movies_not_watched = movie_df[~movie_df['id'].isin(movies_watched_by_user.movieId.values)]['id']
movies_not_watched = list(
    set(movies_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movies_not_watched = [[movie_to_movie_encoded.get(x)] for x in movies_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
)

# Prediksi rating buat film yang belum ditonton
ratings = model.predict(user_movie_array).flatten()

# Ambil top 10 rekomendasi
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movies_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for user:', user_id)
print('===' * 9)
print('Movies with high ratings from user')
print('----' * 8)

# Tampilkan film yang paling tinggi rating-nya dari user itu
top_movies_user = (
    movies_watched_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movies_user)]
for row in movie_df_rows.itertuples():
    print(row.title, '-', row.genre)

print('----' * 8)
print('Top 10 movie recommendations')
print('----' * 8)

recommended_movies = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movies.itertuples():
    print(row.title, '-', row.genre)

"""## **3. Hasil Evaluasi**
- Nilai RMSE pada data pelatihan akhir: sekitar 0.12
- Nilai RMSE pada data validasi: sekitar 0.23
- Kisaran RMSE selama pelatihan: 0.12 – 0.26
Model collaborative filtering menunjukkan proses pelatihan yang stabil dan konvergen pada sekitar epoch ke-50. Nilai RMSE yang cukup rendah menunjukkan bahwa model mampu memprediksi rating pengguna dengan akurasi yang baik.

**Kesimpulan:**
Dengan hasil RMSE yang rendah, model collaborative filtering terbukti efektif dalam memahami pola preferensi pengguna berdasarkan interaksi historis. Model ini sangat berguna dalam memberikan prediksi rating yang akurat, yang menjadi dasar dalam menyusun daftar rekomendasi.
"""